import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc
import matplotlib.pyplot as plt
import os
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer # Para lematiza√ß√£o
from sklearn.naive_bayes import MultinomialNB # Para Naive Bayes

# Certifique-se de baixar as stopwords e o wordnet do NLTK uma vez:
# nltk.download('stopwords')
# nltk.download('wordnet')
# nltk.download('omw-1.4') # Open Multilingual Wordnet, √∫til para lematiza√ß√£o

# --- Fun√ß√µes Auxiliares ---
def limpar_console():
    os.system('cls' if os.name == 'nt' else 'clear')

# Inicializa o lematizador fora da fun√ß√£o para melhor performance
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    """
    Limpeza de texto e lematiza√ß√£o:
    - Converte para min√∫sculas.
    - Remove caracteres n√£o alfanum√©ricos (mant√©m espa√ßos).
    - Remove n√∫meros.
    - Remove stopwords em ingl√™s E portugu√™s.
    - Aplica lematiza√ß√£o.
    """
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text) # Remove caracteres n√£o alfab√©ticos
    text = re.sub(r'\d+', '', text) # Remove n√∫meros

    words = text.split()
    
    # Carrega stopwords de ingl√™s e portugu√™s
    english_stopwords = set(stopwords.words('english'))
    portuguese_stopwords = set(stopwords.words('portuguese'))
    all_stopwords = english_stopwords.union(portuguese_stopwords)

    # Remove stopwords e aplica lematiza√ß√£o
    filtered_words = [lemmatizer.lemmatize(word) for word in words if word not in all_stopwords]
    text = ' '.join(filtered_words)

    return text

# --- 1. Carregamento e Pr√©-processamento de Dados do Kaggle ---
print("--- Carregando e Pr√©-processando Dados do Dataset IMBD ---")

file_path = 'IMBD.csv'

try:
    df = pd.read_csv(file_path)
    print(f"Dataset carregado com sucesso de '{file_path}'")
    print(f"N√∫mero de amostras originais: {len(df)}")
    print("Colunas do dataset:", df.columns.tolist())
    print("Exemplo das primeiras 5 linhas:\n", df.head())
    print("-" * 40)
except FileNotFoundError:
    print(f"ERRO: O arquivo '{file_path}' n√£o foi encontrado.")
    print("Por favor, certifique-se de que voc√™ baixou 'IMBD.csv' do Kaggle")
    print("e o colocou na mesma pasta deste script Python.")
    exit()
except Exception as e:
    print(f"Ocorreu um erro ao carregar ou inspecionar o CSV: {e}")
    exit()

# Verificar e lidar com colunas nulas ou ausentes
required_columns = ['description', 'genre', 'rating', 'title']
for col in required_columns:
    if col not in df.columns:
        print(f"ERRO: Coluna '{col}' n√£o encontrada no dataset.")
        print("Verifique se voc√™ baixou o dataset correto do Kaggle e os nomes das colunas.")
        exit()

# Remover linhas com valores nulos nas colunas que usaremos para o modelo
df.dropna(subset=['description', 'genre', 'rating', 'title'], inplace=True)
print(f"N√∫mero de amostras ap√≥s remover nulos nas colunas essenciais: {len(df)}")

# --- DEFININDO SENTIMENTO COM BASE NA COLUNA 'rating' ---
# Limiar para classifica√ß√£o: rating >= 7.0 √© considerado positivo, < 7.0 √© negativo
RATING_THRESHOLD = 7.0
df['sentiment'] = df['rating'].apply(lambda x: 'positive' if x >= RATING_THRESHOLD else 'negative')

# Mapear sentimentos para n√∫meros (0: negative, 1: positive)
sentiment_mapping = {'negative': 0, 'positive': 1}
df['sentiment_encoded'] = df['sentiment'].map(sentiment_mapping)


df['genre'] = df['genre'].fillna('')

df['combined_text_feature'] = df['description'] + " " + df['genre'] 

# Aplicar pr√©-processamento de texto √† nova coluna 'combined_text_feature'
print("Aplicando pr√©-processamento de texto √† coluna combinada (descri√ß√£o + g√™nero)...")
df['processed_combined_text_feature'] = df['combined_text_feature'].apply(preprocess_text)
print("Pr√©-processamento conclu√≠do.")

X_text = df['processed_combined_text_feature']
y_sentiment = df['sentiment_encoded']

# --- 2. Divis√£o Treino/Teste ---
print("-" * 40)
print("Dividindo dados em conjuntos de treino e teste...")
X_train_text, X_test_text, y_train, y_test, _, X_test_original_title = train_test_split(
    X_text, y_sentiment, df['title'],
    test_size=0.2, random_state=42, stratify=y_sentiment
)

print(f"Dados de Treino: {len(X_train_text)} amostras")
print(f"Dados de Teste: {len(X_test_text)} amostras")
print("-" * 40)

# --- 3. Vetoriza√ß√£o com TF-IDF (com N-grams) ---
print("Treinando TF-IDF Vectorizer (com N-grams)...")
# Adicionado ngram_range=(1, 2) para incluir unigrams e bigrams
tfidf_vectorizer = TfidfVectorizer(max_features=10000, min_df=2, ngram_range=(1, 2))

X_train_vectorized = tfidf_vectorizer.fit_transform(X_train_text)
X_test_vectorized = tfidf_vectorizer.transform(X_test_text)

print(f"TF-IDF Vectorizer treinado. N√∫mero de features: {X_train_vectorized.shape[1]}")
print("-" * 40)

# --- 4. Treinamento dos Modelos (Regress√£o Log√≠stica e Naive Bayes) ---
print("Treinando Modelo de Regress√£o Log√≠stica...")
# Adicionado class_weight='balanced'
logistic_model = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42, class_weight='balanced')
logistic_model.fit(X_train_vectorized, y_train)
print("Modelo de Regress√£o Log√≠stica treinado com sucesso!")

print("\nTreinando Modelo Multinomial Naive Bayes...")
# MultinomialNB √© bom para contagens/frequ√™ncias (TF-IDF)
naive_bayes_model = MultinomialNB()
naive_bayes_model.fit(X_train_vectorized, y_train)
print("Modelo Multinomial Naive Bayes treinado com sucesso!")
print("-" * 40)

# --- 5. Avalia√ß√£o dos Modelos ---
print("--- Avalia√ß√£o do Modelo de Regress√£o Log√≠stica no Conjunto de Teste ---")
y_pred_logistic = logistic_model.predict(X_test_vectorized)
y_pred_proba_logistic = logistic_model.predict_proba(X_test_vectorized)

print(f"Acur√°cia (Regress√£o Log√≠stica) no conjunto de teste: {accuracy_score(y_test, y_pred_logistic):.2f}")
print("\nRelat√≥rio de Classifica√ß√£o (Regress√£o Log√≠stica):\n", classification_report(y_test, y_pred_logistic, target_names=['negative_rating', 'positive_rating']))

fpr_logistic, tpr_logistic, _ = roc_curve(y_test, y_pred_proba_logistic[:, 1])
auc_score_logistic = auc(fpr_logistic, tpr_logistic)
print(f"AUC (Regress√£o Log√≠stica): {auc_score_logistic:.2f}")

# Plotar ROC para Regress√£o Log√≠stica
plt.figure(figsize=(8, 6))
plt.plot(fpr_logistic, tpr_logistic, color='blue', lw=2, label=f'Curva ROC Regress√£o Log√≠stica (AUC = {auc_score_logistic:.2f})')
plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Classificador Aleat√≥rio')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos (False Positive Rate)')
plt.ylabel('Taxa de Verdadeiros Positivos (True Positive Rate)')
plt.title('Curva ROC para Classifica√ß√£o de Sentimento (Regress√£o Log√≠stica)')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

print("-" * 40)
print("\n--- Avalia√ß√£o do Modelo Multinomial Naive Bayes no Conjunto de Teste ---")
y_pred_nb = naive_bayes_model.predict(X_test_vectorized)
y_pred_proba_nb = naive_bayes_model.predict_proba(X_test_vectorized)

print(f"Acur√°cia (Naive Bayes) no conjunto de teste: {accuracy_score(y_test, y_pred_nb):.2f}")
print("\nRelat√≥rio de Classifica√ß√£o (Naive Bayes):\n", classification_report(y_test, y_pred_nb, target_names=['negative_rating', 'positive_rating']))

fpr_nb, tpr_nb, _ = roc_curve(y_test, y_pred_proba_nb[:, 1])
auc_score_nb = auc(fpr_nb, tpr_nb)
print(f"AUC (Naive Bayes): {auc_score_nb:.2f}")

# Plotar ROC para Naive Bayes
plt.figure(figsize=(8, 6))
plt.plot(fpr_nb, tpr_nb, color='red', lw=2, label=f'Curva ROC Naive Bayes (AUC = {auc_score_nb:.2f})')
plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Classificador Aleat√≥rio')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa de Falsos Positivos (False Positive Rate)')
plt.ylabel('Taxa de Verdadeiros Positivos (True Positive Rate)')
plt.title('Curva ROC para Classifica√ß√£o de Sentimento (Multinomial Naive Bayes)')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

print("-" * 40)

# --- 6. Fun√ß√£o de Classifica√ß√£o Interativa ---
def classificar_sentimento_interativo(model_to_use, model_name): # Recebe o modelo e seu nome
    limpar_console()
    print(f"## Classificador Probabil√≠stico de Filmes (Baseado em Nota IMDb) - Modelo: {model_name} ##")
    print("-------------------------------------------------------------------")
    print("Este modelo prev√™ a probabilidade de um filme ter uma nota IMDb alta (>7.0) ou baixa (<7.0).")
    print("Voc√™ pode inserir o nome do filme, sua descri√ß√£o e seus g√™neros.")
    print("Ex: 'O Poderoso Chef√£o'")
    print("Descri√ß√£o: 'Uma epopeia sobre a fam√≠lia Corleone, que ascende ao poder na m√°fia de Nova York.'")
    print("G√™neros: 'Crime, Drama, M√°fia'")
    print("Ou digite 'sair' para encerrar.")
    print("-------------------------------------------------------------------")

    reverse_sentiment_mapping = {v: k for k, v in sentiment_mapping.items()}

    while True:
        title_input = input("\nNome do Filme/S√©rie (ou 'sair'): ").strip()
        if title_input.lower() == 'sair':
            print("Obrigado por usar o recomendador! At√© mais.")
            break

        description_input = input("Descri√ß√£o do Filme/S√©rie: ").strip()
        genre_input = input("G√™neros (separados por v√≠rgula, Ex: A√ß√£o, Drama): ").strip()

        if not description_input and not genre_input:
            print("Por favor, digite a descri√ß√£o e/ou os g√™neros para a an√°lise.")
            continue

        try:
            combined_input = description_input + " " + genre_input
            processed_input = preprocess_text(combined_input)
            input_vetorized = tfidf_vectorizer.transform([processed_input])

            if input_vetorized.sum() == 0:
                print("N√£o consegui reconhecer nenhuma palavra da sua entrada no meu vocabul√°rio. Tente uma descri√ß√£o/g√™nero mais detalhada ou comum.")
                print("Lembre-se que palavras muito raras ou que n√£o foram vistas no treinamento podem ser ignoradas.")
                continue

            probabilidades = model_to_use.predict_proba(input_vetorized)[0]
            prob_negativo_rating = probabilidades[0]
            prob_positivo_rating = probabilidades[1]

            previsao_encoded = model_to_use.predict(input_vetorized)[0]
            previsao_sentimento = reverse_sentiment_mapping[previsao_encoded]

            print("\n--- An√°lise Probabil√≠stica para o Filme ---")
            print(f"Filme/S√©rie: '{title_input}'")
            print(f"Descri√ß√£o: '{description_input}'")
            print(f"G√™neros Analisados: '{genre_input}'")
            print(f"Probabilidade de ter **NOTA BAIXA** (<{RATING_THRESHOLD:.1f}): {prob_negativo_rating:.2%}")
            print(f"Probabilidade de ter **NOTA ALTA** (>={RATING_THRESHOLD:.1f}): {prob_positivo_rating:.2%}")
            
            if previsao_sentimento == 'positive':
                print(f"\n**Previs√£o:** üéâ **PROVAVELMENTE √â UM FILME/S√âRIE BEM AVALIADO!** üéâ")
            else:
                print(f"\n**Previs√£o:** üòî **PROVAVELMENTE √â UM FILME/S√âRIE COM NOTA BAIXA.** üòî")

            print("\n-------------------------------------------------------------------")
            input("Pressione Enter para continuar...")
            limpar_console()
            print(f"## Classificador Probabil√≠stico de Filmes (Baseado em Nota IMDb) - Modelo: {model_name} ##")
            print("-------------------------------------------------------------------")
            print("Digite os dados de outro filme/s√©rie ou 'sair' para encerrar.")
            print("-------------------------------------------------------------------")

        except Exception as e:
            print(f"Ocorreu um erro: {e}. Tente novamente.")
            print(f"Detalhes do erro: {e}")
            continue

# --- Iniciar a aplica√ß√£o ---
if __name__ == "__main__":
    # Permite ao usu√°rio escolher qual modelo usar
    while True:
        limpar_console()
        print("Escolha o modelo para a classifica√ß√£o interativa:")
        print("1. Regress√£o Log√≠stica")
        print("2. Multinomial Naive Bayes")
        print("3. Sair")
        choice = input("Digite o n√∫mero da sua escolha: ").strip()

        if choice == '1':
            classificar_sentimento_interativo(logistic_model, "Regress√£o Log√≠stica")
            break # Sai do loop de escolha ap√≥s o uso do classificador
        elif choice == '2':
            classificar_sentimento_interativo(naive_bayes_model, "Multinomial Naive Bayes")
            break # Sai do loop de escolha ap√≥s o uso do classificador
        elif choice == '3':
            print("Encerrando o programa.")
            break
        else:
            print("Escolha inv√°lida. Por favor, digite 1, 2 ou 3.")
            input("Pressione Enter para continuar...")