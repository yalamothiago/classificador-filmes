import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc
import matplotlib.pyplot as plt
import os
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.naive_bayes import MultinomialNB
import gradio as gr # Import Gradio

# Certifique-se de baixar as stopwords e o wordnet do NLTK uma vez:
# nltk.download('stopwords')
# nltk.download('wordnet')
# nltk.download('omw-1.4') # Open Multilingual Wordnet, √∫til para lematiza√ß√£o

# --- Fun√ß√µes Auxiliares ---
# A fun√ß√£o limpar_console n√£o √© necess√°ria para a aplica√ß√£o web

# Inicializa o lematizador fora da fun√ß√£o para melhor performance
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    """
    Limpeza de texto e lematiza√ß√£o:
    - Converte para min√∫sculas.
    - Remove caracteres n√£o alfanum√©ricos (mant√©m espa√ßos).
    - Remove n√∫meros.
    - Remove stopwords em ingl√™s E portugu√™s.
    - Aplica lematiza√ß√£o.
    """
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text) # Remove caracteres n√£o alfab√©ticos
    text = re.sub(r'\d+', '', text) # Remove n√∫meros

    words = text.split()
    
    # Carrega stopwords de ingl√™s e portugu√™s
    english_stopwords = set(stopwords.words('english'))
    portuguese_stopwords = set(stopwords.words('portuguese'))
    all_stopwords = english_stopwords.union(portuguese_stopwords)

    # Remove stopwords e aplica lematiza√ß√£o
    filtered_words = [lemmatizer.lemmatize(word) for word in words if word not in all_stopwords]
    text = ' '.join(filtered_words)

    return text

# --- 1. Carregamento e Pr√©-processamento de Dados do Kaggle ---
print("--- Carregando e Pr√©-processando Dados do Dataset IMBD ---")

file_path = 'IMBD.csv'

try:
    df = pd.read_csv(file_path)
    print(f"Dataset carregado com sucesso de '{file_path}'")
    print(f"N√∫mero de amostras originais: {len(df)}")
    print("Colunas do dataset:", df.columns.tolist())
    print("Exemplo das primeiras 5 linhas:\n", df.head())
    print("-" * 40)
except FileNotFoundError:
    print(f"ERRO: O arquivo '{file_path}' n√£o foi encontrado.")
    print("Por favor, certifique-se de que voc√™ baixou 'IMBD.csv' do Kaggle")
    print("e o colocou na mesma pasta deste script Python.")
    exit()
except Exception as e:
    print(f"Ocorreu um erro ao carregar ou inspecionar o CSV: {e}")
    exit()

# Verificar e lidar com colunas nulas ou ausentes
required_columns = ['description', 'genre', 'rating', 'title']
for col in required_columns:
    if col not in df.columns:
        print(f"ERRO: Coluna '{col}' n√£o encontrada no dataset.")
        print("Verifique se voc√™ baixou o dataset correto do Kaggle e os nomes das colunas.")
        exit()

# Remover linhas com valores nulos nas colunas que usaremos para o modelo
df.dropna(subset=['description', 'genre', 'rating', 'title'], inplace=True)
print(f"N√∫mero de amostras ap√≥s remover nulos nas colunas essenciais: {len(df)}")

# --- DEFININDO SENTIMENTO COM BASE NA COLUNA 'rating' ---
# Limiar para classifica√ß√£o: rating >= 7.0 √© considerado positivo, < 7.0 √© negativo
RATING_THRESHOLD = 7.0
df['sentiment'] = df['rating'].apply(lambda x: 'positive' if x >= RATING_THRESHOLD else 'negative')

# Mapear sentimentos para n√∫meros (0: negative, 1: positive)
sentiment_mapping = {'negative': 0, 'positive': 1}
df['sentiment_encoded'] = df['sentiment'].map(sentiment_mapping)


df['genre'] = df['genre'].fillna('')

df['combined_text_feature'] = df['description'] + " " + df['genre'] 

# Aplicar pr√©-processamento de texto √† nova coluna 'combined_text_feature'
print("Aplicando pr√©-processamento de texto √† coluna combinada (descri√ß√£o + g√™nero)...")
df['processed_combined_text_feature'] = df['combined_text_feature'].apply(preprocess_text)
print("Pr√©-processamento conclu√≠do.")

X_text = df['processed_combined_text_feature']
y_sentiment = df['sentiment_encoded']

# --- 2. Divis√£o Treino/Teste ---
print("-" * 40)
print("Dividindo dados em conjuntos de treino e teste...")
X_train_text, X_test_text, y_train, y_test = train_test_split(
    X_text, y_sentiment,
    test_size=0.2, random_state=42, stratify=y_sentiment
)

print(f"Dados de Treino: {len(X_train_text)} amostras")
print(f"Dados de Teste: {len(X_test_text)} amostras")
print("-" * 40)

# --- 3. Vetoriza√ß√£o com TF-IDF (com N-grams) ---
print("Treinando TF-IDF Vectorizer (com N-grams)...")
# Adicionado ngram_range=(1, 2) para incluir unigrams e bigrams
tfidf_vectorizer = TfidfVectorizer(max_features=10000, min_df=2, ngram_range=(1, 2))

X_train_vectorized = tfidf_vectorizer.fit_transform(X_train_text)
X_test_vectorized = tfidf_vectorizer.transform(X_test_text)

print(f"TF-IDF Vectorizer treinado. N√∫mero de features: {X_train_vectorized.shape[1]}")
print("-" * 40)

# --- 4. Treinamento dos Modelos (Regress√£o Log√≠stica e Naive Bayes) ---
print("Treinando Modelo de Regress√£o Log√≠stica...")
# Adicionado class_weight='balanced'
logistic_model = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42, class_weight='balanced')
logistic_model.fit(X_train_vectorized, y_train)
print("Modelo de Regress√£o Log√≠stica treinado com sucesso!")

print("\nTreinando Modelo Multinomial Naive Bayes...")
# MultinomialNB √© bom para contagens/frequ√™ncias (TF-IDF)
naive_bayes_model = MultinomialNB()
naive_bayes_model.fit(X_train_vectorized, y_train)
print("Modelo Multinomial Naive Bayes treinado com sucesso!")
print("-" * 40)

# --- 5. Avalia√ß√£o dos Modelos (Opcional para a aplica√ß√£o web, mas mantido para contexto) ---
# Voc√™ pode comentar esta se√ß√£o se quiser um script mais leve para a web app,
# mas √© √∫til para verificar o desempenho antes de implantar.

print("--- Avalia√ß√£o do Modelo de Regress√£o Log√≠stica no Conjunto de Teste ---")
y_pred_logistic = logistic_model.predict(X_test_vectorized)
y_pred_proba_logistic = logistic_model.predict_proba(X_test_vectorized)
print(f"Acur√°cia (Regress√£o Log√≠stica) no conjunto de teste: {accuracy_score(y_test, y_pred_logistic):.2f}")
print("\nRelat√≥rio de Classifica√ß√£o (Regress√£o Log√≠stica):\n", classification_report(y_test, y_pred_logistic, target_names=['negative_rating', 'positive_rating']))
fpr_logistic, tpr_logistic, _ = roc_curve(y_test, y_pred_proba_logistic[:, 1])
auc_score_logistic = auc(fpr_logistic, tpr_logistic)
print(f"AUC (Regress√£o Log√≠stica): {auc_score_logistic:.2f}")

print("-" * 40)
print("\n--- Avalia√ß√£o do Modelo Multinomial Naive Bayes no Conjunto de Teste ---")
y_pred_nb = naive_bayes_model.predict(X_test_vectorized)
y_pred_proba_nb = naive_bayes_model.predict_proba(X_test_vectorized)
print(f"Acur√°cia (Naive Bayes) no conjunto de teste: {accuracy_score(y_test, y_pred_nb):.2f}")
print("\nRelat√≥rio de Classifica√ß√£o (Naive Bayes):\n", classification_report(y_test, y_pred_nb, target_names=['negative_rating', 'positive_rating']))
fpr_nb, tpr_nb, _ = roc_curve(y_test, y_pred_proba_nb[:, 1])
auc_score_nb = auc(fpr_nb, tpr_nb)
print(f"AUC (Naive Bayes): {auc_score_nb:.2f}")
print("-" * 40)


# --- Fun√ß√£o para a Interface Gradio ---
def classify_movie_sentiment(model_choice, title_input, description_input, genre_input):
    """
    Classifica o sentimento de um filme (probabilidade de nota alta/baixa)
    usando o modelo escolhido e retorna o resultado formatado para Gradio.
    """
    if model_choice == "Regress√£o Log√≠stica":
        model_to_use = logistic_model
        model_name = "Regress√£o Log√≠stica"
    elif model_choice == "Multinomial Naive Bayes":
        model_to_use = naive_bayes_model
        model_name = "Multinomial Naive Bayes"
    else:
        return "Erro: Modelo inv√°lido selecionado."

    if not description_input and not genre_input:
        return "Por favor, digite a descri√ß√£o e/ou os g√™neros para a an√°lise."

    combined_input = description_input + " " + genre_input
    processed_input = preprocess_text(combined_input)
    input_vetorized = tfidf_vectorizer.transform([processed_input])

    if input_vetorized.sum() == 0:
        return "N√£o consegui reconhecer nenhuma palavra da sua entrada no meu vocabul√°rio. Tente uma descri√ß√£o/g√™nero mais detalhada ou comum.<br>Lembre-se que palavras muito raras ou que n√£o foram vistas no treinamento podem ser ignoradas."

    probabilidades = model_to_use.predict_proba(input_vetorized)[0]
    prob_negativo_rating = probabilidades[0]
    prob_positivo_rating = probabilidades[1]

    previsao_encoded = model_to_use.predict(input_vetorized)[0]
    reverse_sentiment_mapping = {v: k for k, v in sentiment_mapping.items()}
    previsao_sentimento = reverse_sentiment_mapping[previsao_encoded]

    # Formatando a sa√≠da para Gradio com HTML para melhor visual
    output_html = f"<h3>--- An√°lise Probabil√≠stica para o Filme ---</h3>"
    output_html += f"<p><strong>Filme/S√©rie:</strong> '{title_input}'</p>"
    output_html += f"<p><strong>Descri√ß√£o:</strong> '{description_input}'</p>"
    output_html += f"<p><strong>G√™neros Analisados:</strong> '{genre_input}'</p>"
    output_html += f"<p>Probabilidade de ter <b>NOTA BAIXA</b> (&lt;{RATING_THRESHOLD:.1f}): <span style='color:red; font-weight:bold;'>{prob_negativo_rating:.2%}</span></p>"
    output_html += f"<p>Probabilidade de ter <b>NOTA ALTA</b> (&gt;={RATING_THRESHOLD:.1f}): <span style='color:green; font-weight:bold;'>{prob_positivo_rating:.2%}</span></p>"
    
    if previsao_sentimento == 'positive':
        output_html += f"<p style='font-size: 1.2em; text-align: center; margin-top: 20px;'>üéâ <strong>PROVAVELMENTE √â UM FILME/S√âRIE BEM AVALIADO!</strong> üéâ</p>"
    else:
        output_html += f"<p style='font-size: 1.2em; text-align: center; margin-top: 20px;'>üòî <strong>PROVAVELMENTE √â UM FILME/S√âRIE COM NOTA BAIXA.</strong> üòî</p>"

    return output_html

# --- Configura√ß√£o da Interface Gradio ---
if __name__ == "__main__":
    # Remove as chamadas plt.show() para evitar que as janelas pop-up apare√ßam ao iniciar a web app
    # Se voc√™ quiser ver as curvas ROC, execute o script sem a parte do Gradio ou adicione-as
    # como um componente de visualiza√ß√£o separada no Gradio, se necess√°rio.

    # Cria a interface Gradio
    interface = gr.Interface(
        fn=classify_movie_sentiment,
        inputs=[
            gr.Dropdown(["Regress√£o Log√≠stica", "Multinomial Naive Bayes"], label="Escolha o Modelo"),
            gr.Textbox(label="Nome do Filme/S√©rie", placeholder="Ex: O Poderoso Chef√£o"),
            gr.Textbox(label="Descri√ß√£o do Filme/S√©rie", placeholder="Ex: Uma epopeia sobre a fam√≠lia Corleone, que ascende ao poder na m√°fia de Nova York."),
            gr.Textbox(label="G√™neros (separados por v√≠rgula)", placeholder="Ex: Crime, Drama, M√°fia")
        ],
        outputs=gr.HTML(), # Usa gr.HTML para exibir o conte√∫do HTML formatado
        title="Classificador Probabil√≠stico de Filmes (Baseado em Nota IMDb)",
        description="Este modelo prev√™ a probabilidade de um filme/s√©rie ter uma nota IMDb alta (>=7.0) ou baixa (<7.0). "
                    "Insira o nome, descri√ß√£o e g√™neros para obter uma previs√£o."
    )

    # Lan√ßa a interface Gradio
    interface.launch()